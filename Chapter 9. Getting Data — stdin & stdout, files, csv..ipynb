{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9. Getting Data\n",
    "## stdin and stdout\n",
    "If you run your Python scripts at the command line, you can pipe data through them using sys.stdin and sys.stdout. For example, here is a script that reads in lines of text and spits back out the ones that match a regular expression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# egrep.py\n",
    "import sys, re\n",
    "\n",
    "# sys.argv is the list of command-line arguments\n",
    "# sys.argv[0] is the name of the program itself\n",
    "# sys.argv[1] will be the regex specified at the command line\n",
    "regex = sys.argv[1]\n",
    "\n",
    "# for every line passed into the script\n",
    "for line in sys.stdin:\n",
    "    # if it matches the regex, write it to stdout\n",
    "    if re.search(regex, line):\n",
    "        sys.stdout.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here’s one that counts the lines it receives and then writes out the count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line_count.py\n",
    "import sys\n",
    "\n",
    "count = 0\n",
    "for line in sys.stdin:\n",
    "    count += 1\n",
    "\n",
    "# print goes to sys.stdout\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could then use these to count how many lines of a file contain numbers.\n",
    "* Windows: type SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py\n",
    "* Linux: cat SomeFile.txt | python egrep.py \"[0-9]\" | python line_count.py\n",
    "\n",
    "The | is the pipe character, which means “use the output of the left command as the input\n",
    "of the right command.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts the words in its input and writes out the most common ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_words.py\n",
    "import sys\n",
    "from collections import Counter\n",
    "\n",
    "# pass in number of words as first argument\n",
    "try:\n",
    "    num_words = int(sys.argv[1])\n",
    "except:\n",
    "    print(\"usage: most_common_words.py num_words\")\n",
    "    sys.exit(1) # non-zero exit code indicates error\n",
    "\n",
    "counter = Counter(word.lower()                         # lowercase words\n",
    "                  for line in sys.stdin                #\n",
    "                  for word in line.strip().split()     # split on spaces\n",
    "                  if word)                             # skip empty 'words'\n",
    "\n",
    "for word, count in counter.most_common(num_words):\n",
    "    sys.stdout.write(str(count))\n",
    "    sys.stdout.write(\"\\t\")\n",
    "    sys.stdout.write(word)\n",
    "    sys.stdout.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after which you could do something like: <br>\n",
    "cat the_bible.txt | python most_common_words.py 10 <br>\n",
    "<img src='https://i.imgur.com/e1XkiGo.jpg' width='100px' style='float:left'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Files\n",
    "### The Basics of Text Files\n",
    "The first step to working with a text file is to obtain a *file object* using **open()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'r' means read-only\n",
    "file_for_reading = open('reading_file.txt', 'r')\n",
    "\n",
    "# 'w' is write—will destroy the file if it already exists!\n",
    "file_for_writing = open('writing_file.txt', 'w')\n",
    "\n",
    "# 'a' is append—for adding to the end of the file\n",
    "file_for_appending = open('appending_file.txt', 'a')\n",
    "\n",
    "# don't forget to close your files when you're done\n",
    "file_for_writing.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it is easy to forget to close your files, you should always use them in a **with** block, at the end of which they will be closed automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e615418629f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction_that_gets_data_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# at this point f has already been closed, so don't try to use it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "with open(filename,'r') as f:\n",
    "    data = function_that_gets_data_from(f)\n",
    "\n",
    "    # at this point f has already been closed, so don't try to use it\n",
    "process(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to read a whole text file, you can just iterate over the lines of the file using **for**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "starts_with_hash = 0\n",
    "\n",
    "with open('the_bible.txt', 'r') as file:\n",
    "    for line in file:  # look at each line in the file\n",
    "        if re.match(\"^#\", line):  # use a regex to see if it starts w\n",
    "            starts_with_hash += 1  # if it does, add 1 to the count\n",
    "\n",
    "print(starts_with_hash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every line you get this way ends in a newline character, so you’ll often want to **strip()** itbefore doing anything with it.\n",
    "\n",
    "For example, imagine you have a file full of email addresses, one per line, and that youneed to generate a histogram of the domains. The rules for correctly extracting domainsare somewhat subtle (e.g., the Public Suffix List), but a good first approximation is to justtake the parts of the email addresses that come after the @ . (Which gives the wrong answerfor email addresses like joel@mail.datasciencester.com .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def get_domain(email_address):\n",
    "    \"\"\"split on '@' and return the last piece\"\"\"\n",
    "    return email_address.lower().split(\"@\")[-1]\n",
    "# For example, \"abdul_rainbolt1@aol.com\".split(\"@\")\n",
    "# abdul_rainbolt1 — [0]  aol.com — [1]\n",
    "# [-1] — first from the end, which is the same as [1] in this case.\n",
    "\n",
    "with open('email_addresses.txt', 'r') as f:\n",
    "    domain_counts = Counter(get_domain(line.strip())\n",
    "                            for line in f\n",
    "                            if \"@\" in line)\n",
    "print(domain_counts)\n",
    "# Output will be smth like this:\n",
    "# Counter({'aol.com': 61, 'outlook.com': 61, 'hotmail.com': 49, 'yahoo.com': 45})\n",
    "\n",
    "# If no line.strip(), that is no trimming spaces, then: \n",
    "# Counter({'aol.com\\n': 61, 'outlook.com\\n': 61, 'hotmail.com\\n': 48, 'yahoo.com\\n': 45})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimited Files. CSV\n",
    "The hypothetical email addresses file we just processed had one address per line. Morefrequently you’ll work with files with lots of data on each line. These files are very ofteneither *comma-separated* or *tab-separated*. Each line has several fields, with a comma (or atab) indicating where one field ends and the next field starts.\n",
    "\n",
    "This starts to get complicated when you have fields with commas and tabs and newlines inthem (which you inevitably do). For this reason, it’s pretty much always a mistake to try toparse them yourself. Instead, you should use Python’s csv module (or the pandas library)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For technical reasons that you should feel free to blame on Microsoft, you should alwayswork with *csv* files in *binary mode* by including a **b** after the **r** or **w** (see Stack Overflow). There's no problems without binary mode on ubuntu.\n",
    "\n",
    "If your file has no headers (which means you probably want each row as a *list* , and which places the burden on you to know what’s in each column), you can use **csv.reader()** to iterate over the rows, each of which will be an appropriately split list.\n",
    "\n",
    "For example, if we had a comma-delimited file of stock prices: <br>\n",
    "6/20/2014,AAPL,90.91 <br>\n",
    "6/20/2014,MSFT,41.68 <br>\n",
    "6/20/2014,FB,64.5 <br>\n",
    "6/19/2014,AAPL,91.86 <br>\n",
    "6/19/2014,MSFT,41.51 <br>\n",
    "6/19/2014,FB,4.34 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'comma_delimited_stock_prices.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7424fd176e90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'comma_delimited_stock_prices.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msymbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'comma_delimited_stock_prices.txt'"
     ]
    }
   ],
   "source": [
    "with open('comma_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    for row in reader:\n",
    "        date = row[0]\n",
    "        symbol = row[1]\n",
    "        closing_price = float(row[2])\n",
    "        print(date, symbol, closing_price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your file has headers: <br>\n",
    "date:symbol:closing_price <br>\n",
    "6/20/2014:AAPL:90.91 <br>\n",
    "6/20/2014:MSFT:41.68 <br> \n",
    "6/20/2014:FB:64.5 <br>\n",
    "\n",
    "you can either skip the header row (with an initial call to **reader.next()** ) or get each row as a dict (with the headers as keys) by using **csv.DictReader()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('colon_delimited_stock_prices.txt', 'r') as f:\n",
    "    reader = csv.DictReader(f, delimiter=':')\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        closing_price = float(row[\"closing_price\"])\n",
    "        print(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if your file doesn’t have headers you can still use **DictReader()** by passing it the keys as a **fieldnames** parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('comma_delimited_stock_prices.txt', 'r') as f:\n",
    "    fieldnames = ['date', 'symbol', 'closing_price']\n",
    "    reader = csv.DictReader(f, delimiter=',', fieldnames=fieldnames)\n",
    "    for row in reader:\n",
    "        date = row[\"date\"]\n",
    "        symbol = row[\"symbol\"]\n",
    "        closing_price = float(row[\"closing_price\"])\n",
    "        print(date, symbol, closing_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can similarly write out delimited data using **csv.writer()**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today_prices = {'AAPL': 90.91, 'MSFT': 41.68, 'FB': 64.5}\n",
    "\n",
    "with open('comma_delimited_stock_prices2.txt', 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    for stock, price in today_prices.items():\n",
    "        writer.writerow([stock, price])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**csv.writer()** will do the right thing if your fields themselves have commas in them. Your own hand-rolled writer probably won’t. For example, if you attempt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [[\"test1\",\"success\", \"Monday\"],\n",
    "           [\"test2\",\"success, kind of\", \"Tuesday\"],\n",
    "           [\"test3\",\"failure, kind of\", \"Wednesday\"]\n",
    "           [\"test4\",\"failure, utter\", \"Thursday\"]]\n",
    "\n",
    "\n",
    "# don't do this!\n",
    "with open('bad_csv.txt', 'wb') as f:\n",
    "    for row in results:\n",
    "        f.write(\",\".join(map(str, row)))  # might have too many commas in it!\n",
    "        f.write(\"\\n\")  # row might have newlines as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will end up with a csv file that looks like: <br> <br>\n",
    "test1,success,Monday <br>\n",
    "test2,success, kind of,Tuesday <br>\n",
    "test3,failure, kind of,Wednesday <br>\n",
    "test4,failure, utter,Thursday <br>\n",
    "\n",
    "and that no one will ever be able to make sense of."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
